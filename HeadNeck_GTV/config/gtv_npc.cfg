[dataset]

data_fold = 0
data_scale = small
weight_training = 1.0
config_csv_dir = config/cross_validation
data_root_dir = ../../Dataset_Rad

# modality number
modal_num = 1

# data transforms
# train_transform = [ExtractPatches, RandomFlip]
train_transform = [RandomCrop, RandomFlip]
valid_transform  = [Donothing]
test_transform  = [Donothing]

RandomCrop_output_size = [32,64,64] 

RandomCrop_inverse     = False

RandomFlip_flip_depth = False
RandomFlip_flip_height = False
RandomFlip_flip_width = False
RandomFlip_inverse = True

Donothing_do = True


[network]
# this section gives parameters for network
# the keys may be different for different networks

# type of network
# net_type = Baseunet2d5_att_pe
# net_type = VNet
net_type = UNet2D5
# net_type = URPC
# net_type = UNet2D5_PE
# net_type = UNet3D
# net_type = UNet3DGenesis
# net_type = Rest_UNet3D++

# number of class, required for segmentation task
class_num     = 2
in_chns       = 1
# feature_chns  = [8, 16, 32, 64, 128]
feature_chns  = [16, 32, 64, 128, 256]
# feature_chns  = [32, 64, 128, 256, 512]
acti_func     = leakyrelu
leakyrelu_negative_slope = 0.01
dropout       = False

use_pretrain = False

[training]
# device name" cuda:n or cpu
device_name = cuda:0
train_rand_crop = True

#Batch size of 16 for UNetGenesis
batch_size    = 64
#64 for 32 slice, and 128 for 64 slice
slice_length  = 128 
loss_function = dice_loss
# for optimizers
optimizer     = Adam
learning_rate = 5e-4
momentum      = 0.9
weight_decay  = 1e-5
genesis_lr = 1e-4
lr_gamma      = 0.5
# lr_milestones = [100,200,300,400,500]
lr_milestones = [500,800,1200,1700]
checkpoint_prefix = model

use_pretrain = False
pretrained_model_path = None #.pt

# start iter
iter_start = 0
iter_max   = 50000
max_epoch = 1501


[testing]
# device name" cuda:n or cpu
device_name = cuda:2

mini_patch_shape = None
mini_batch_size   = 1

label_source = None
label_target = None

output_dir = result
save_probability = False


[SSL]
# device name" cuda:n or cpu
#RPL-Input-Size
input_size = 4096
num_class = 26
hidden_size = 1024
include_top = False
submodel = fullybig
encoder = Unet2D5
algorithm = rpl-rot
ssl_transform = rotation

[finetuning]
warm_up_epoch = -1
